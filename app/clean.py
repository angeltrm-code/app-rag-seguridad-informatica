#!/usr/bin/env python3
"""
app/clean.py ‚Äî Limpieza y normalizaci√≥n de Markdown

Aplica reglas anti-ruido (¬ß4.1) al Markdown extra√≠do:
- Elimina dot leaders (√≠ndices con puntos)
- Colapsa espacios/tabs/saltos m√∫ltiples in√∫tiles
- Elimina cabeceras/pies repetitivos
- Repara guiones de salto de l√≠nea
- Preserva bloques de c√≥digo, rutas, CVEs, comandos (¬ß4.2)

Uso:
    python -m app.clean
    make clean
"""

import re
import sys
from pathlib import Path
from collections import Counter

from app.utils import (
    load_config,
    require_pdfs,
    ensure_dir,
    print_header,
    PROJECT_ROOT,
)


# ‚îÄ‚îÄ Patrones anti-ruido ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

# Dot leaders: "CAP√çTULO 3 .................................. 45"
RE_DOT_LEADERS = re.compile(
    r"^.*?\.{4,}\s*\d*\s*$", re.MULTILINE
)

# Secuencias de espacios in√∫tiles (m√°s de 3 espacios seguidos)
RE_EXCESS_SPACES = re.compile(r"[ \t]{4,}")

# M√∫ltiples l√≠neas en blanco (m√°s de 2)
RE_EXCESS_NEWLINES = re.compile(r"\n{4,}")

# Guiones de salto de l√≠nea: "imple-\nmentaci√≥n" ‚Üí "implementaci√≥n"
RE_HYPHEN_BREAK = re.compile(r"(\w)-\n(\w)")

# L√≠neas que son solo espacios/tabs
RE_BLANK_LINES = re.compile(r"^[ \t]+$", re.MULTILINE)

# Numeraci√≥n de p√°gina suelta: solo un n√∫mero en una l√≠nea
RE_PAGE_NUMBER = re.compile(r"^\s*\d{1,4}\s*$", re.MULTILINE)


def detect_repeated_headers_footers(text: str, threshold: int = 3) -> list[str]:
    """
    Detecta l√≠neas que se repiten demasiadas veces (cabeceras/pies).

    Args:
        text: Texto completo del documento.
        threshold: N√∫mero m√≠nimo de repeticiones para considerar ruido.

    Returns:
        Lista de l√≠neas repetitivas a eliminar.
    """
    lines = text.split("\n")
    counter = Counter()

    for line in lines:
        stripped = line.strip()
        # Solo contar l√≠neas no vac√≠as y que no sean headers Markdown
        if stripped and not stripped.startswith("#") and not stripped.startswith("<!--"):
            counter[stripped] += 1

    # L√≠neas que aparecen m√°s veces que el umbral
    repeated = [line for line, count in counter.items() if count >= threshold]
    return repeated


def is_code_block(lines: list[str], idx: int) -> bool:
    """Determina si la l√≠nea est√° dentro de un bloque de c√≥digo."""
    in_code = False
    for i in range(idx):
        if lines[i].strip().startswith("```"):
            in_code = not in_code
    return in_code


def clean_markdown(text: str) -> tuple[str, dict]:
    """
    Aplica reglas de limpieza al texto Markdown.

    Returns:
        Tupla de (texto limpio, m√©tricas de limpieza).
    """
    original_len = len(text)
    metrics = {
        "original_chars": original_len,
        "dot_leaders_removed": 0,
        "repeated_lines_removed": 0,
        "hyphen_breaks_fixed": 0,
        "excess_spaces_collapsed": 0,
    }

    # 1. Eliminar dot leaders
    matches = RE_DOT_LEADERS.findall(text)
    metrics["dot_leaders_removed"] = len(matches)
    text = RE_DOT_LEADERS.sub("", text)

    # 2. Detectar y eliminar headers/footers repetitivos
    repeated = detect_repeated_headers_footers(text)
    for line in repeated:
        count_before = text.count(line)
        text = text.replace(line + "\n", "")
        metrics["repeated_lines_removed"] += count_before

    # 3. Reparar guiones de salto de l√≠nea
    fixed = RE_HYPHEN_BREAK.findall(text)
    metrics["hyphen_breaks_fixed"] = len(fixed)
    text = RE_HYPHEN_BREAK.sub(r"\1\2", text)

    # 4. Colapsar espacios excesivos (fuera de bloques de c√≥digo)
    lines = text.split("\n")
    cleaned_lines = []
    in_code = False
    for line in lines:
        if line.strip().startswith("```"):
            in_code = not in_code
        if not in_code:
            new_line = RE_EXCESS_SPACES.sub(" ", line)
            if new_line != line:
                metrics["excess_spaces_collapsed"] += 1
            line = new_line
        cleaned_lines.append(line)
    text = "\n".join(cleaned_lines)

    # 5. Limpiar l√≠neas que son solo espacios
    text = RE_BLANK_LINES.sub("", text)

    # 6. Eliminar n√∫meros de p√°gina sueltos
    text = RE_PAGE_NUMBER.sub("", text)

    # 7. Colapsar saltos de l√≠nea excesivos
    text = RE_EXCESS_NEWLINES.sub("\n\n\n", text)

    # 8. Trim final
    text = text.strip() + "\n"

    metrics["clean_chars"] = len(text)
    metrics["reduction_percent"] = round(
        (1 - len(text) / max(original_len, 1)) * 100, 1
    )

    return text, metrics


def main():
    print_header("LIMPIEZA DE MARKDOWN")
    require_pdfs("limpieza")

    config = load_config()
    input_dir = PROJECT_ROOT / config["paths"]["extracted_md"]
    output_dir = PROJECT_ROOT / config["paths"]["clean_md"]
    ensure_dir(output_dir)

    md_files = sorted(input_dir.glob("*.md"))

    if not md_files:
        print("  No hay archivos Markdown en 02_extracted_md/ para limpiar.")
        print("  Ejecute primero: make extract")
        return

    print(f"  Procesando {len(md_files)} archivo(s)...\n")

    all_metrics = []
    for md_file in md_files:
        with open(md_file, "r", encoding="utf-8") as f:
            text = f.read()

        clean_text, metrics = clean_markdown(text)
        metrics["file"] = md_file.name

        output_file = output_dir / md_file.name
        with open(output_file, "w", encoding="utf-8") as f:
            f.write(clean_text)

        print(f"  üìù {md_file.name}: {metrics['reduction_percent']}% reducido "
              f"({metrics['dot_leaders_removed']} dot-leaders, "
              f"{metrics['hyphen_breaks_fixed']} guiones reparados)")

        all_metrics.append(metrics)

    # Resumen
    total_reduction = sum(m["reduction_percent"] for m in all_metrics) / max(len(all_metrics), 1)
    print(f"\n  Reducci√≥n media: {total_reduction:.1f}%")
    print("  Siguiente paso: make chunk")


if __name__ == "__main__":
    main()
